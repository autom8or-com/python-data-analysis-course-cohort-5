{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 Wednesday - Part 1: Data Merging with Pandas\n",
    "\n",
    "**Duration:** 45 minutes  \n",
    "**Topic:** Combining Multiple DataFrames using `merge()`  \n",
    "**Business Context:** Lagos E-Commerce Inventory Management  \n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "\n",
    "1. Understand the relationship between SQL JOINs and pandas `merge()`\n",
    "2. Perform inner, left, right, and outer joins using pandas\n",
    "3. Merge multiple datasets to create comprehensive inventory analysis\n",
    "4. Handle common merging issues (duplicate keys, missing values, column name conflicts)\n",
    "5. Apply merge operations to real-world inventory management scenarios\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction: Why Merging Matters\n",
    "\n",
    "In real-world data analysis, information is rarely contained in a single table. For inventory management:\n",
    "\n",
    "- **Products table:** Contains product details (weight, dimensions, category)\n",
    "- **Inventory table:** Contains stock levels and warehouse locations\n",
    "- **Orders table:** Contains sales transactions\n",
    "- **Suppliers table:** Contains supplier information\n",
    "\n",
    "To answer business questions like:\n",
    "- \"Which high-demand products are low in stock?\"\n",
    "- \"What's the average inventory value by warehouse?\"\n",
    "- \"Which suppliers provide the best-selling products?\"\n",
    "\n",
    "We need to **combine (merge)** these separate tables into unified datasets.\n",
    "\n",
    "---\n",
    "\n",
    "## Setup: Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Display settings for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets\n",
    "products = pd.read_csv('../datasets/products.csv')\n",
    "inventory = pd.read_csv('../datasets/inventory.csv')\n",
    "orders = pd.read_csv('../datasets/orders.csv')\n",
    "order_items = pd.read_csv('../datasets/order_items.csv')\n",
    "suppliers = pd.read_csv('../datasets/suppliers.csv')\n",
    "warehouses = pd.read_csv('../datasets/warehouses.csv')\n",
    "\n",
    "print(\"‚úì Datasets loaded successfully\")\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Products: {len(products)} rows\")\n",
    "print(f\"  Inventory: {len(inventory)} rows\")\n",
    "print(f\"  Orders: {len(orders)} rows\")\n",
    "print(f\"  Order Items: {len(order_items)} rows\")\n",
    "print(f\"  Suppliers: {len(suppliers)} rows\")\n",
    "print(f\"  Warehouses: {len(warehouses)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview each dataset\n",
    "print(\"PRODUCTS:\")\n",
    "print(products.head(3))\n",
    "print(\"\\nINVENTORY:\")\n",
    "print(inventory.head(3))\n",
    "print(\"\\nWAREHOUSES:\")\n",
    "print(warehouses.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1: SQL JOIN ‚Üî Pandas Merge Mapping (10 minutes)\n",
    "\n",
    "### The Four Types of Joins\n",
    "\n",
    "| SQL JOIN Type | Pandas Parameter | Result | Use Case |\n",
    "|---------------|------------------|--------|----------|\n",
    "| `INNER JOIN` | `how='inner'` | Only matching records | Find products with active inventory |\n",
    "| `LEFT JOIN` | `how='left'` | All from left + matches from right | Keep all products, show inventory where available |\n",
    "| `RIGHT JOIN` | `how='right'` | All from right + matches from left | Keep all inventory, add product details |\n",
    "| `FULL OUTER JOIN` | `how='outer'` | All records from both tables | Identify data gaps (products without inventory) |\n",
    "\n",
    "### Basic Syntax Comparison\n",
    "\n",
    "**SQL:**\n",
    "```sql\n",
    "SELECT *\n",
    "FROM products p\n",
    "INNER JOIN inventory i ON p.product_id = i.product_id;\n",
    "```\n",
    "\n",
    "**Pandas:**\n",
    "```python\n",
    "result = pd.merge(products, inventory, on='product_id', how='inner')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Section 2: Inner Join - Matching Records Only (10 minutes)\n",
    "\n",
    "**Business Question:** \"Show me products that currently have inventory, with their stock levels\"\n",
    "\n",
    "### Example 1: Products with Active Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join: Only products that have inventory records\n",
    "products_with_inventory = pd.merge(\n",
    "    products,\n",
    "    inventory,\n",
    "    on='product_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Products in dataset: {len(products)}\")\n",
    "print(f\"Inventory records: {len(inventory)}\")\n",
    "print(f\"Products with inventory (after INNER join): {len(products_with_inventory)}\")\n",
    "print(\"\\nSample result:\")\n",
    "print(products_with_inventory[['product_id', 'category', 'stock_level', 'status']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Add Warehouse Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain multiple merges to add warehouse details\n",
    "inventory_with_location = pd.merge(\n",
    "    products_with_inventory,\n",
    "    warehouses,\n",
    "    on='warehouse_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"Records after adding warehouse info: {len(inventory_with_location)}\")\n",
    "print(\"\\nInventory by warehouse:\")\n",
    "print(inventory_with_location[['product_id', 'category', 'stock_level', 'city', 'region']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Key Insight:** Inner joins reduce your dataset to only matching records. This is useful when you only want complete data.\n",
    "\n",
    "---\n",
    "\n",
    "## Section 3: Left Join - Keep All Records from Left Table (10 minutes)\n",
    "\n",
    "**Business Question:** \"Show me ALL products, and their inventory status (even if they don't have inventory)\"\n",
    "\n",
    "### Example 3: All Products with Optional Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left join: Keep all products, add inventory data where available\n",
    "all_products_inventory = pd.merge(\n",
    "    products,\n",
    "    inventory,\n",
    "    on='product_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Total products: {len(all_products_inventory)}\")\n",
    "print(f\"Products WITHOUT inventory: {all_products_inventory['stock_level'].isna().sum()}\")\n",
    "print(\"\\nSample with missing inventory:\")\n",
    "print(all_products_inventory[all_products_inventory['stock_level'].isna()].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Values After Left Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing stock levels with 0 for products not in inventory\n",
    "all_products_inventory['stock_level'] = all_products_inventory['stock_level'].fillna(0)\n",
    "all_products_inventory['status'] = all_products_inventory['status'].fillna('Not Tracked')\n",
    "\n",
    "print(\"Stock level distribution after filling NaN:\")\n",
    "print(all_products_inventory['status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Key Insight:** Left joins preserve all records from the left DataFrame. Missing matches result in NaN values that need to be handled.\n",
    "\n",
    "---\n",
    "\n",
    "## Section 4: Right Join and Outer Join (8 minutes)\n",
    "\n",
    "### Example 4: Right Join - Keep All Inventory Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right join: Keep all inventory, add product details where available\n",
    "all_inventory_products = pd.merge(\n",
    "    products,\n",
    "    inventory,\n",
    "    on='product_id',\n",
    "    how='right'\n",
    ")\n",
    "\n",
    "print(f\"Inventory records preserved: {len(all_inventory_products)}\")\n",
    "print(f\"Inventory without product details: {all_inventory_products['category'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Outer Join - Keep Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outer join: Keep all products AND all inventory records\n",
    "full_product_inventory = pd.merge(\n",
    "    products,\n",
    "    inventory,\n",
    "    on='product_id',\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "print(f\"Total records (outer join): {len(full_product_inventory)}\")\n",
    "print(f\"Products without inventory: {full_product_inventory['stock_level'].isna().sum()}\")\n",
    "print(f\"Inventory without product: {full_product_inventory['category'].isna().sum()}\")\n",
    "\n",
    "# Identify orphaned inventory (no matching product)\n",
    "orphaned_inventory = full_product_inventory[full_product_inventory['category'].isna()]\n",
    "print(f\"\\n‚ö†Ô∏è Data Quality Issue: {len(orphaned_inventory)} inventory records have no matching product!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Key Insight:** Outer joins are excellent for data quality checks - they reveal orphaned records and data inconsistencies.\n",
    "\n",
    "---\n",
    "\n",
    "## Section 5: Advanced Merging Techniques (7 minutes)\n",
    "\n",
    "### Handling Column Name Conflicts with Suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When both tables have columns with the same name (besides the key)\n",
    "# Use suffixes to distinguish them\n",
    "result_with_suffixes = pd.merge(\n",
    "    inventory,\n",
    "    warehouses,\n",
    "    on='warehouse_id',\n",
    "    how='left',\n",
    "    suffixes=('_inventory', '_warehouse')\n",
    ")\n",
    "\n",
    "print(\"Columns after merge with suffixes:\")\n",
    "print(result_with_suffixes.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging on Different Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the joining columns have different names in each table\n",
    "# Example: order_items has 'seller_id', suppliers has 'supplier_id'\n",
    "items_with_suppliers = pd.merge(\n",
    "    order_items,\n",
    "    suppliers,\n",
    "    left_on='seller_id',\n",
    "    right_on='supplier_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Order items with supplier info: {len(items_with_suppliers)}\")\n",
    "print(\"\\nSample:\")\n",
    "print(items_with_suppliers[['order_id', 'seller_id', 'city', 'state']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging on Multiple Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes you need to match on multiple columns for uniqueness\n",
    "# Example: Match products and inventory by both product_id AND warehouse_id\n",
    "# (This is hypothetical since our inventory already has warehouse_id)\n",
    "\n",
    "# Syntax example:\n",
    "# result = pd.merge(df1, df2, on=['col1', 'col2'], how='inner')\n",
    "\n",
    "print(\"Syntax for multi-column merge:\")\n",
    "print(\"pd.merge(df1, df2, on=['key1', 'key2'], how='inner')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Real-World Business Analysis (5 minutes)\n",
    "\n",
    "**Complete Example:** Create a comprehensive inventory report with all relevant information\n",
    "\n",
    "### Multi-Step Merge: Products ‚Üí Inventory ‚Üí Warehouses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Merge products with inventory (left join to keep all products)\n",
    "step1 = pd.merge(products, inventory, on='product_id', how='left')\n",
    "\n",
    "# Step 2: Add warehouse details (left join to preserve products without inventory)\n",
    "inventory_report = pd.merge(step1, warehouses, on='warehouse_id', how='left')\n",
    "\n",
    "# Clean up the result\n",
    "inventory_report['stock_level'] = inventory_report['stock_level'].fillna(0)\n",
    "inventory_report['status'] = inventory_report['status'].fillna('Not in Inventory')\n",
    "inventory_report['city'] = inventory_report['city'].fillna('Not Assigned')\n",
    "\n",
    "print(\"Complete Inventory Report:\")\n",
    "print(inventory_report[[\n",
    "    'product_id', 'category', 'stock_level', \n",
    "    'status', 'city', 'region'\n",
    "]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Insights from Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can answer complex business questions\n",
    "\n",
    "# 1. Which warehouse has the most inventory?\n",
    "print(\"Total Stock by Warehouse:\")\n",
    "print(inventory_report.groupby('city')['stock_level'].sum().sort_values(ascending=False))\n",
    "\n",
    "# 2. Which product categories are low in stock?\n",
    "print(\"\\nLow Stock Products by Category:\")\n",
    "low_stock = inventory_report[inventory_report['status'] == 'Low Stock']\n",
    "print(low_stock['category'].value_counts())\n",
    "\n",
    "# 3. Which region has the most product variety?\n",
    "print(\"\\nProduct Variety by Region:\")\n",
    "print(inventory_report.groupby('region')['product_id'].nunique().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Key Takeaways\n",
    "\n",
    "### What We Learned Today:\n",
    "\n",
    "1. **Merge Types:**\n",
    "   - `how='inner'`: Only matching records (intersection)\n",
    "   - `how='left'`: All from left table + matches from right\n",
    "   - `how='right'`: All from right table + matches from left\n",
    "   - `how='outer'`: All records from both tables (union)\n",
    "\n",
    "2. **Key Parameters:**\n",
    "   - `on`: Column name(s) to join on\n",
    "   - `left_on` / `right_on`: Different column names\n",
    "   - `suffixes`: Handle column name conflicts\n",
    "\n",
    "3. **Best Practices:**\n",
    "   - Always check record counts before and after merging\n",
    "   - Handle missing values (NaN) after left/right/outer joins\n",
    "   - Use outer joins to identify data quality issues\n",
    "   - Chain merges step-by-step for complex analyses\n",
    "\n",
    "### SQL to Pandas Quick Reference:\n",
    "\n",
    "```python\n",
    "# SQL: INNER JOIN\n",
    "pd.merge(df1, df2, on='key', how='inner')\n",
    "\n",
    "# SQL: LEFT JOIN\n",
    "pd.merge(df1, df2, on='key', how='left')\n",
    "\n",
    "# SQL: RIGHT JOIN\n",
    "pd.merge(df1, df2, on='key', how='right')\n",
    "\n",
    "# SQL: FULL OUTER JOIN\n",
    "pd.merge(df1, df2, on='key', how='outer')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Practice Exercise (5 minutes)\n",
    "\n",
    "**Challenge:** Merge `orders`, `order_items`, and `products` to answer:\n",
    "\"What product categories are generating the most revenue?\"\n",
    "\n",
    "### Your Task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Merge orders with order_items\n",
    "# Step 2: Add product information\n",
    "# Step 3: Calculate total revenue by category\n",
    "# Step 4: Sort and display top 5 categories\n",
    "\n",
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution (Reveal After Attempting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution:\n",
    "orders_items = pd.merge(orders, order_items, on='order_id', how='inner')\n",
    "full_sales = pd.merge(orders_items, products, on='product_id', how='left')\n",
    "revenue_by_category = full_sales.groupby('category')['price'].sum().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 5 Revenue-Generating Categories:\")\n",
    "print(revenue_by_category.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Session Preview\n",
    "\n",
    "**Part 2: Data Reshaping (Wednesday, 45 minutes)**\n",
    "- Pivot tables: Convert rows to columns\n",
    "- Melt: Convert wide data to long format\n",
    "- Stack/Unstack: Multi-level reshaping\n",
    "- Real-world use cases: Monthly sales trends, category performance matrices\n",
    "\n",
    "---\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [Pandas merge() documentation](https://pandas.pydata.org/docs/reference/api/pandas.merge.html)\n",
    "- [SQL to pandas comparison](https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html)\n",
    "- Week 10 SQL content (Thursday): Database normalization and views"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
