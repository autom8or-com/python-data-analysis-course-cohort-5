{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 12: Financial Analysis - Python Exercise\n",
    "## Statistical Analysis of Nigerian E-commerce Data\n",
    "\n",
    "### Exercise Overview\n",
    "In this exercise, you will apply statistical analysis techniques to analyze financial performance data from a Nigerian e-commerce marketplace. You will work with real-world data to derive actionable business insights.\n",
    "\n",
    "### Learning Objectives\n",
    "- Apply descriptive statistical analysis to business data\n",
    "- Conduct correlation analysis between financial metrics\n",
    "- Perform statistical testing to validate business hypotheses\n",
    "- Create data visualizations for statistical insights\n",
    "- Translate statistical findings into business recommendations\n",
    "\n",
    "### Scenario\n",
    "You are a data analyst for a Nigerian e-commerce platform. The management team wants to understand:\n",
    "1. How different regions perform financially\n",
    "2. What factors influence customer spending patterns\n",
    "3. Whether there are significant differences in payment preferences across states\n",
    "4. What statistical insights can drive business strategy\n",
    "\n",
    "### Dataset\n",
    "The dataset contains transaction-level data including:\n",
    "- Customer information (state, city)\n",
    "- Transaction details (payment value, payment type)\n",
    "- Timestamps for temporal analysis\n",
    "- Customer segmentation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set styling\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = '/home/odunayo12/python-data-analysis-course-cohort-5/curriculum/02-phase-2-core-skills/weeks-09-12-advanced/week-12-financial-analysis-reporting/wednesday-python/lecture-materials/datasets/financial_analysis_data.csv'\n",
    "\n",
    "# Load data into DataFrame\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully!\")\n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head())\n",
    "    print(\"\\nColumn information:\")\n",
    "    print(df.info())\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Please check the file path.\")\n",
    "    # Create sample data for exercise\n",
    "    np.random.seed(42)\n",
    "    states = ['SP', 'RJ', 'MG', 'BA', 'RS']\n",
    "    payment_types = ['credit_card', 'boleto', 'debit_card']\n",
    "    segments = ['Standard', 'Silver', 'Gold', 'Platinum']\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'customer_id': [f'customer_{i:04d}' for i in range(1, 101)],\n",
    "        'customer_state': np.random.choice(states, 100),\n",
    "        'customer_city': [f'City_{i}' for i in range(1, 101)],\n",
    "        'payment_value': np.random.normal(150, 50, 100),\n",
    "        'payment_type': np.random.choice(payment_types, 100),\n",
    "        'order_purchase_timestamp': pd.date_range('2018-01-01', periods=100, freq='D'),\n",
    "        'payment_installments': np.random.randint(1, 7, 100),\n",
    "        'customer_segment': np.random.choice(segments, 100)\n",
    "    })\n",
    "    print(\"Created sample data for exercise.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "print(\"=== DATA PREPROCESSING ===\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Convert timestamp column to datetime\n",
    "if 'order_purchase_timestamp' in df.columns:\n",
    "    df['order_purchase_timestamp'] = pd.to_datetime(df['order_purchase_timestamp'])\n",
    "    df['order_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['order_day_of_week'] = df['order_purchase_timestamp'].dt.day_name()\n",
    "\n",
    "# Basic data statistics\n",
    "print(\"\\n=== BASIC STATISTICS ===\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Regional Performance Analysis\n",
    "\n",
    "**Exercise 2.1:** Calculate comprehensive statistics for each Nigerian state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Calculate regional statistics\n",
    "# Create a function to calculate comprehensive statistics for each state\n",
    "\n",
    "def calculate_regional_stats(dataframe):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive statistics for each state.\n",
    "    Returns: DataFrame with state-level statistics\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass\n",
    "\n",
    "# Call your function and display results\n",
    "# regional_stats = calculate_regional_stats(df)\n",
    "# print(regional_stats)\n",
    "\n",
    "print(\"Implement the calculate_regional_stats function above to continue...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2.2:** Create visualizations to compare regional performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Create regional performance visualizations\n",
    "# Create subplots for regional analysis\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Regional Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Average order value by state\n",
    "# Your code here\n",
    "\n",
    "# 2. Total revenue by state\n",
    "# Your code here\n",
    "\n",
    "# 3. Transaction count by state\n",
    "# Your code here\n",
    "\n",
    "# 4. Payment type distribution by state\n",
    "# Your code here\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Implement the visualization code above to continue...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Statistical Analysis\n",
    "\n",
    "**Exercise 3.1:** Perform correlation analysis between different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Correlation analysis\n",
    "\n",
    "# 1. Calculate correlation matrix for numeric variables\n",
    "numeric_cols = ['payment_value', 'payment_installments']\n",
    "if 'order_month' in df.columns:\n",
    "    numeric_cols.append('order_month')\n",
    "\n",
    "# Create correlation matrix\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "# 2. Create correlation heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f')\n",
    "plt.title('Correlation Matrix of Financial Metrics')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Calculate Pearson and Spearman correlations\n",
    "if len(numeric_cols) >= 2:\n",
    "    pearson_corr, pearson_p = pearsonr(df[numeric_cols[0]], df[numeric_cols[1]])\n",
    "    spearman_corr, spearman_p = spearmanr(df[numeric_cols[0]], df[numeric_cols[1]])\n",
    "    \n",
    "    print(f\"\\nPearson Correlation ({numeric_cols[0]} vs {numeric_cols[1]}): {pearson_corr:.3f}, p-value: {pearson_p:.3f}\")\n",
    "    print(f\"Spearman Correlation ({numeric_cols[0]} vs {numeric_cols[1]}): {spearman_corr:.3f}, p-value: {spearman_p:.3f}\")\n",
    "    \n",
    "    # Interpret correlation\n",
    "    if abs(pearson_corr) > 0.7:\n",
    "        strength = \"Strong\"\n",
    "    elif abs(pearson_corr) > 0.3:\n",
    "        strength = \"Moderate\"\n",
    "    else:\n",
    "        strength = \"Weak\"\n",
    "    \n",
    "    direction = \"positive\" if pearson_corr > 0 else \"negative\"\n",
    "    print(f\"Interpretation: {strength} {direction} correlation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.2:** Conduct statistical tests to validate business hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Statistical hypothesis testing\n",
    "\n",
    "# Hypothesis 1: Do credit card transactions have higher average values than boleto transactions?\n",
    "credit_card_values = df[df['payment_type'] == 'credit_card']['payment_value']\n",
    "boleto_values = df[df['payment_type'] == 'boleto']['payment_value']\n",
    "\n",
    "if len(credit_card_values) > 0 and len(boleto_values) > 0:\n",
    "    # Perform t-test\n",
    "    t_stat, p_value = stats.ttest_ind(credit_card_values, boleto_values)\n",
    "    \n",
    "    print(f\"T-test: Credit Card vs Boleto\")\n",
    "    print(f\"T-statistic: {t_stat:.3f}\")\n",
    "    print(f\"P-value: {p_value:.3f}\")\n",
    "    print(f\"Credit Card Mean: â‚¦{credit_card_values.mean():.2f}\")\n",
    "    print(f\"Boleto Mean: â‚¦{boleto_values.mean():.2f}\")\n",
    "    \n",
    "    # Interpretation\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(f\"Result: Significant difference (p < {alpha})\")\n",
    "        if credit_card_values.mean() > boleto_values.mean():\n",
    "            print(\"Conclusion: Credit card transactions have significantly higher average values\")\n",
    "        else:\n",
    "            print(\"Conclusion: Boleto transactions have significantly higher average values\")\n",
    "    else:\n",
    "        print(f\"Result: No significant difference (p >= {alpha})\")\n",
    "        print(\"Conclusion: No statistically significant difference between payment types\")\n",
    "\n",
    "# Hypothesis 2: Is there a significant difference in spending between different states?\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ANOVA Test: Payment Values by State\")\n",
    "\n",
    "states = df['customer_state'].unique()\n",
    "state_groups = [df[df['customer_state'] == state]['payment_value'] for state in states if len(df[df['customer_state'] == state]) > 0]\n",
    "\n",
    "if len(state_groups) >= 2:\n",
    "    # Perform ANOVA test\n",
    "    f_stat, p_value_anova = stats.f_oneway(*state_groups)\n",
    "    \n",
    "    print(f\"F-statistic: {f_stat:.3f}\")\n",
    "    print(f\"P-value: {p_value_anova:.3f}\")\n",
    "    \n",
    "    # Show means by state\n",
    "    print(\"\\nAverage payment by state:\")\n",
    "    for state in states:\n",
    "        state_mean = df[df['customer_state'] == state]['payment_value'].mean()\n",
    "        print(f\"{state}: â‚¦{state_mean:.2f}\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if p_value_anova < alpha:\n",
    "        print(f\"\\nResult: Significant difference between states (p < {alpha})\")\n",
    "        print(\"Conclusion: There are significant differences in spending patterns across states\")\n",
    "    else:\n",
    "        print(f\"\\nResult: No significant difference between states (p >= {alpha})\")\n",
    "        print(\"Conclusion: No statistically significant difference in spending across states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Advanced Analysis\n",
    "\n",
    "**Exercise 4.1:** Customer segmentation based on statistical patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Advanced customer segmentation\n",
    "\n",
    "# Create customer-level metrics\n",
    "customer_metrics = df.groupby('customer_id').agg({\n",
    "    'payment_value': ['sum', 'mean', 'count', 'std'],\n",
    "    'customer_state': 'first',\n",
    "    'payment_type': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "customer_metrics.columns = ['total_spent', 'avg_order_value', 'order_count', 'spending_std', 'state', 'preferred_payment_type']\n",
    "\n",
    "# Calculate additional metrics\n",
    "customer_metrics['spending_cv'] = (customer_metrics['spending_std'] / customer_metrics['avg_order_value']) * 100\n",
    "customer_metrics['avg_order_frequency'] = customer_metrics['order_count']  # Simplified for this dataset\n",
    "\n",
    "# Fill NaN values in spending_cv (for customers with single order)\n",
    "customer_metrics['spending_cv'] = customer_metrics['spending_cv'].fillna(0)\n",
    "\n",
    "print(\"Customer Metrics Summary:\")\n",
    "print(customer_metrics.describe())\n",
    "\n",
    "# Create customer segments based on statistical patterns\n",
    "def create_statistical_segments(row):\n",
    "    \"\"\"\n",
    "    Create customer segments based on statistical patterns\n",
    "    \"\"\"\n",
    "    # Your segmentation logic here\n",
    "    if row['total_spent'] > customer_metrics['total_spent'].quantile(0.75):\n",
    "        if row['spending_cv'] < 50:\n",
    "            return 'High Value - Consistent'\n",
    "        else:\n",
    "            return 'High Value - Variable'\n",
    "    elif row['total_spent'] > customer_metrics['total_spent'].quantile(0.50):\n",
    "        if row['spending_cv'] < 50:\n",
    "            return 'Medium Value - Consistent'\n",
    "        else:\n",
    "            return 'Medium Value - Variable'\n",
    "    else:\n",
    "        if row['spending_cv'] < 50:\n",
    "            return 'Low Value - Consistent'\n",
    "        else:\n",
    "            return 'Low Value - Variable'\n",
    "\n",
    "customer_metrics['statistical_segment'] = customer_metrics.apply(create_statistical_segments, axis=1)\n",
    "\n",
    "print(\"\\nSegment Distribution:\")\n",
    "print(customer_metrics['statistical_segment'].value_counts())\n",
    "\n",
    "# Visualize segments\n",
    "plt.figure(figsize=(12, 6))\n",
    "segment_colors = sns.color_palette(\"husl\", len(customer_metrics['statistical_segment'].unique()))\n",
    "customer_metrics['statistical_segment'].value_counts().plot(kind='bar', color=segment_colors)\n",
    "plt.title('Customer Segments Based on Statistical Patterns')\n",
    "plt.xlabel('Segment')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.2:** Outlier detection and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Outlier detection and analysis\n",
    "\n",
    "# Method 1: IQR (Interquartile Range) Method\n",
    "def detect_outliers_iqr(data, column):\n",
    "    \"\"\"\n",
    "    Detect outliers using IQR method\n",
    "    \"\"\"\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Method 2: Z-score Method\n",
    "def detect_outliers_zscore(data, column, threshold=3):\n",
    "    \"\"\"\n",
    "    Detect outliers using Z-score method\n",
    "    \"\"\"\n",
    "    z_scores = np.abs(stats.zscore(data[column]))\n",
    "    outliers = data[z_scores > threshold]\n",
    "    return outliers\n",
    "\n",
    "# Detect outliers in payment values\n",
    "outliers_iqr, lower_bound, upper_bound = detect_outliers_iqr(df, 'payment_value')\n",
    "outliers_zscore = detect_outliers_zscore(df, 'payment_value', threshold=3)\n",
    "\n",
    "print(\"=== OUTLIER ANALYSIS ===\")\n",
    "print(f\"IQR Method:\")\n",
    "print(f\"  Lower bound: â‚¦{lower_bound:.2f}\")\n",
    "print(f\"  Upper bound: â‚¦{upper_bound:.2f}\")\n",
    "print(f\"  Outliers detected: {len(outliers_iqr)}\")\n",
    "\n",
    "print(f\"\\nZ-score Method (threshold=3):\")\n",
    "print(f\"  Outliers detected: {len(outliers_zscore)}\")\n",
    "\n",
    "# Analyze outliers\n",
    "if len(outliers_iqr) > 0:\n",
    "    print(f\"\\nOutlier Analysis (IQR Method):\")\n",
    "    print(f\"  Average outlier value: â‚¦{outliers_iqr['payment_value'].mean():.2f}\")\n",
    "    print(f\"  State distribution:\")\n",
    "    print(outliers_iqr['customer_state'].value_counts())\n",
    "    print(f\"  Payment type distribution:\")\n",
    "    print(outliers_iqr['payment_type'].value_counts())\n",
    "\n",
    "# Visualize outliers\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Box plot by state\n",
    "plt.subplot(1, 2, 1)\n",
    "df.boxplot(column='payment_value', by='customer_state', ax=plt.gca())\n",
    "plt.title('Payment Distribution by State')\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "# Histogram with outlier bounds\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df['payment_value'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.axvline(lower_bound, color='red', linestyle='--', label='Lower Bound')\n",
    "plt.axvline(upper_bound, color='red', linestyle='--', label='Upper Bound')\n",
    "plt.axvline(df['payment_value'].mean(), color='green', linestyle='-', label='Mean')\n",
    "plt.xlabel('Payment Value (â‚¦)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Payment Value Distribution with Outlier Bounds')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Business Insights and Recommendations\n",
    "\n",
    "**Exercise 5.1:** Create a comprehensive statistical summary with business insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE: Business insights generation\n",
    "\n",
    "def generate_business_insights(dataframe):\n",
    "    \"\"\"\n",
    "    Generate business insights based on statistical analysis\n",
    "    \"\"\"\n",
    "    insights = []\n",
    "    \n",
    "    # 1. Revenue analysis\n",
    "    total_revenue = dataframe['payment_value'].sum()\n",
    "    avg_order_value = dataframe['payment_value'].mean()\n",
    "    total_transactions = len(dataframe)\n",
    "    \n",
    "    insights.append({\n",
    "        'category': 'Revenue Performance',\n",
    "        'metric': 'Total Revenue',\n",
    "        'value': f'â‚¦{total_revenue:,.2f}',\n",
    "        'insight': f'Total revenue of â‚¦{total_revenue:,.0f} from {total_transactions} transactions'\n",
    "    })\n",
    "    \n",
    "    insights.append({\n",
    "        'category': 'Revenue Performance',\n",
    "        'metric': 'Average Order Value',\n",
    "        'value': f'â‚¦{avg_order_value:.2f}',\n",
    "        'insight': f'Average order value of â‚¦{avg_order_value:.2f} indicates customer spending patterns'\n",
    "    })\n",
    "    \n",
    "    # 2. Regional insights\n",
    "    regional_performance = dataframe.groupby('customer_state')['payment_value'].agg(['sum', 'mean', 'count']).round(2)\n",
    "    top_state = regional_performance['sum'].idxmax()\n",
    "    highest_avg_state = regional_performance['mean'].idxmax()\n",
    "    \n",
    "    insights.append({\n",
    "        'category': 'Regional Analysis',\n",
    "        'metric': 'Top Revenue State',\n",
    "        'value': top_state,\n",
    "        'insight': f'{top_state} generates the highest revenue at â‚¦{regional_performance.loc[top_state, \"sum\"]:,.0f}'\n",
    "    })\n",
    "    \n",
    "    insights.append({\n",
    "        'category': 'Regional Analysis',\n",
    "        'metric': 'Highest Average Order',\n",
    "        'value': highest_avg_state,\n",
    "        'insight': f'{highest_avg_state} has the highest average order value at â‚¦{regional_performance.loc[highest_avg_state, \"mean\"]:.2f}'\n",
    "    })\n",
    "    \n",
    "    # 3. Payment method insights\n",
    "    payment_analysis = dataframe.groupby('payment_type')['payment_value'].agg(['sum', 'mean', 'count']).round(2)\n",
    "    preferred_payment = payment_analysis['sum'].idxmax()\n",
    "    \n",
    "    insights.append({\n",
    "        'category': 'Payment Analysis',\n",
    "        'metric': 'Preferred Payment Method',\n",
    "        'value': preferred_payment,\n",
    "        'insight': f'{preferred_payment} is the most preferred payment method with â‚¦{payment_analysis.loc[preferred_payment, \"sum\"]:,.0f} in revenue'\n",
    "    })\n",
    "    \n",
    "    # 4. Statistical insights\n",
    "    cv = (dataframe['payment_value'].std() / dataframe['payment_value'].mean()) * 100\n",
    "    \n",
    "    insights.append({\n",
    "        'category': 'Statistical Analysis',\n",
    "        'metric': 'Coefficient of Variation',\n",
    "        'value': f'{cv:.1f}%',\n",
    "        'insight': f'CV of {cv:.1f}% indicates {\"high\" if cv > 50 else \"moderate\" if cv > 25 else \"low\"} variability in order values'\n",
    "    })\n",
    "    \n",
    "    # 5. Risk assessment\n",
    "    outliers_count = len(detect_outliers_iqr(dataframe, 'payment_value')[0])\n",
    "    outlier_percentage = (outliers_count / len(dataframe)) * 100\n",
    "    \n",
    "    insights.append({\n",
    "        'category': 'Risk Assessment',\n",
    "        'metric': 'Outlier Percentage',\n",
    "        'value': f'{outlier_percentage:.1f}%',\n",
    "        'insight': f'{outlier_percentage:.1f}% of transactions are outliers, indicating {\"high\" if outlier_percentage > 5 else \"moderate\" if outlier_percentage > 2 else \"low\"} risk profile'\n",
    "    })\n",
    "    \n",
    "    return pd.DataFrame(insights)\n",
    "\n",
    "# Generate business insights\n",
    "business_insights = generate_business_insights(df)\n",
    "\n",
    "print(\"=== BUSINESS INSIGHTS DASHBOARD ===\")\n",
    "for i, (_, row) in enumerate(business_insights.iterrows()):\n",
    "    print(f\"\\n{i+1}. {row['category']}: {row['metric']}\")\n",
    "    print(f\"   Value: {row['value']}\")\n",
    "    print(f\"   Insight: {row['insight']}\")\n",
    "\n",
    "# Create visual summary\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Business Intelligence Dashboard', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Revenue by payment type\n",
    "payment_revenue = df.groupby('payment_type')['payment_value'].sum()\n",
    "axes[0, 0].pie(payment_revenue.values, labels=payment_revenue.index, autopct='%1.1f%%')\n",
    "axes[0, 0].set_title('Revenue by Payment Type')\n",
    "\n",
    "# Revenue by state\n",
    "state_revenue = df.groupby('customer_state')['payment_value'].sum().sort_values(ascending=False)\n",
    "axes[0, 1].bar(state_revenue.index, state_revenue.values)\n",
    "axes[0, 1].set_title('Revenue by State')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Order value distribution\n",
    "axes[1, 0].hist(df['payment_value'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[1, 0].axvline(df['payment_value'].mean(), color='red', linestyle='--', label='Mean')\n",
    "axes[1, 0].set_title('Order Value Distribution')\n",
    "axes[1, 0].set_xlabel('Order Value (â‚¦)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Transaction trends (if timestamp available)\n",
    "if 'order_purchase_timestamp' in df.columns:\n",
    "    df['order_date'] = df['order_purchase_timestamp'].dt.date\n",
    "    daily_transactions = df.groupby('order_date').size()\n",
    "    axes[1, 1].plot(daily_transactions.index, daily_transactions.values)\n",
    "    axes[1, 1].set_title('Transaction Trends Over Time')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "else:\n",
    "    axes[1, 1].text(0.5, 0.5, 'Temporal analysis\\nrequires timestamp data', \n",
    "                    ha='center', va='center', transform=axes[1, 1].transAxes)\n",
    "    axes[1, 1].set_title('Transaction Trends (N/A)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Executive Summary\n",
    "\n",
    "**Exercise 6.1:** Create an executive summary with strategic recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    # YOUR CODE HERE: Executive summary generation\n",
    "\n",
    "def create_executive_summary(dataframe):\n",
    "    \"\"\"\n",
    "    Create executive summary with strategic recommendations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Key metrics\n",
    "    total_revenue = dataframe['payment_value'].sum()\n",
    "    total_customers = dataframe['customer_id'].nunique()\n",
    "    avg_order_value = dataframe['payment_value'].mean()\n",
    "    \n",
    "    # Top performing regions\n",
    "    regional_stats = dataframe.groupby('customer_state').agg({\n",
    "        'payment_value': ['sum', 'mean', 'count'],\n",
    "        'customer_id': 'nunique'\n",
    "    }).round(2)\n",
    "    \n",
    "    regional_stats.columns = ['total_revenue', 'avg_order_value', 'transactions', 'unique_customers']\n",
    "    regional_stats = regional_stats.sort_values('total_revenue', ascending=False)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"EXECUTIVE SUMMARY: FINANCIAL PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    print()\n",
    "    \n",
    "    print(\"KEY PERFORMANCE INDICATORS:\")\n",
    "    print(f\"â€¢ Total Revenue: â‚¦{total_revenue:,.2f}\")\n",
    "    print(f\"â€¢ Total Customers: {total_customers:,}\")\n",
    "    print(f\"â€¢ Average Order Value: â‚¦{avg_order_value:.2f}\")\n",
    "    print(f\"â€¢ Total Transactions: {len(dataframe):,}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"REGIONAL PERFORMANCE HIGHLIGHTS:\")\n",
    "    for i, (state, stats) in enumerate(regional_stats.head(3).iterrows()):\n",
    "        print(f\"{i+1}. {state}: â‚¦{stats['total_revenue']:,.0f} revenue, \"\n",
    "              f\"{stats['unique_customers']} customers, â‚¦{stats['avg_order_value']:.2f} avg order\")\n",
    "    print()\n",
    "    \n",
    "    print(\"STRATEGIC RECOMMENDATIONS:\")\n",
    "    print()\n",
    "    \n",
    "    # Revenue optimization recommendations\n",
    "    top_state = regional_stats.index[0]\n",
    "    print(\"1. REVENUE OPTIMIZATION:\")\n",
    "    print(f\"   â€¢ Focus growth initiatives on {top_state} (highest revenue state)\")\n",
    "    \n",
    "    # Payment method recommendations\n",
    "    payment_performance = dataframe.groupby('payment_type').agg({\n",
    "        'payment_value': ['sum', 'mean', 'count']\n",
    "    }).round(2)\n",
    "    payment_performance.columns = ['total_revenue', 'avg_order_value', 'transaction_count']\n",
    "    \n",
    "    best_payment_type = payment_performance['total_revenue'].idxmax()\n",
    "    highest_avg_payment = payment_performance['avg_order_value'].idxmax()\n",
    "    \n",
    "    print(f\"   â€¢ Promote {best_payment_type} adoption (highest revenue generation)\")\n",
    "    print(f\"   â€¢ Develop upselling strategies for {highest_avg_payment} users (highest avg order)\")\n",
    "    print()\n",
    "    \n",
    "    # Customer segmentation recommendations\n",
    "    print(\"2. CUSTOMER SEGMENTATION:\")\n",
    "    high_value_threshold = dataframe['payment_value'].quantile(0.75)\n",
    "    high_value_customers = dataframe[dataframe['payment_value'] > high_value_threshold]['customer_id'].nunique()\n",
    "    \n",
    "    print(f\"   â€¢ Target {high_value_customers} high-value customers with premium services\")\n",
    "    print(f\"   â€¢ Implement loyalty programs for customers with orders > â‚¦{high_value_threshold:.0f}\")\n",
    "    print()\n",
    "    \n",
    "    # Risk management recommendations\n",
    "    outliers_count = len(detect_outliers_iqr(dataframe, 'payment_value')[0])\n",
    "    cv = (dataframe['payment_value'].std() / dataframe['payment_value'].mean()) * 100\n",
    "    \n",
    "    print(\"3. RISK MANAGEMENT:\")\n",
    "    if outliers_count > 0:\n",
    "        print(f\"   â€¢ Monitor {outliers_count} outlier transactions for fraud prevention\")\n",
    "    \n",
    "    if cv > 50:\n",
    "        print(f\"   â€¢ High variability (CV: {cv:.1f}%) - implement pricing consistency measures\")\n",
    "    elif cv > 25:\n",
    "        print(f\"   â€¢ Moderate variability (CV: {cv:.1f}%) - monitor market trends\")\n",
    "    else:\n",
    "        print(f\"   â€¢ Low variability (CV: {cv:.1f}%) - stable pricing environment\")\n",
    "    print()\n",
    "    \n",
    "    # Expansion opportunities\n",
    "    print(\"4. EXPANSION OPPORTUNITIES:\")\n",
    "    \n",
    "    # States with potential for growth\n",
    "    underserved_states = regional_stats[regional_stats['avg_order_value'] > avg_order_value]\n",
    "    if len(underserved_states) > 0:\n",
    "        print(f\"   â€¢ Target high-potential states: {list(underserved_states.index)}\")\n",
    "    \n",
    "    # Payment method optimization\n",
    "    underutilized_payments = payment_performance[payment_performance['avg_order_value'] > avg_order_value]\n",
    "    if len(underutilized_payments) > 0:\n",
    "        print(f\"   â€¢ Optimize {list(underutilized_payments.index)} payment methods\")\n",
    "    print()\n",
    "    \n",
    "    print(\"NEXT STEPS:\")\n",
    "    print(\"â€¢ Implement A/B testing for pricing strategies\")\n",
    "    print(\"â€¢ Develop regional marketing campaigns\")\n",
    "    print(\"â€¢ Create customer retention programs\")\n",
    "    print(\"â€¢ Establish monthly performance monitoring\")\n",
    "    print()\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Generated by: Financial Analysis Team\")\n",
    "    print(f\"Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Generate executive summary\n",
    "create_executive_summary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Requirements\n",
    "\n",
    "Please submit the following:\n",
    "\n",
    "1. **Completed Notebook**: All code cells executed with proper outputs\n",
    "2. **Statistical Analysis Report**: Include all calculations and interpretations\n",
    "3. **Business Insights**: At least 5 key insights with supporting data\n",
    "4. **Recommendations**: 3-4 actionable business recommendations\n",
    "5. **Visualizations**: All charts with proper titles and interpretations\n",
    "\n",
    "### Evaluation Criteria\n",
    "- **Technical Accuracy**: Correct implementation of statistical methods (40%)\n",
    "- **Business Insight Quality**: Depth and relevance of insights (30%)\n",
    "- **Visualization Clarity**: Quality and interpretability of charts (20%)\n",
    "- **Code Quality**: Clean, well-commented, and efficient code (10%)\n",
    "\n",
    "### Bonus Points\n",
    "- Advanced statistical methods beyond requirements\n",
    "- Creative visualization approaches\n",
    "- Additional business value insights\n",
    "- Exceptional code documentation\n",
    "\n",
    "### Deadline\n",
    "Submit your completed exercise by the end of the class session.\n",
    "\n",
    "---\n",
    "\n",
    "**Good luck with your analysis!** ðŸ“ŠðŸ‡³ðŸ‡¬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}